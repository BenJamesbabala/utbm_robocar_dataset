<!DOCTYPE html>

<html lang="en">
  <head>
    <meta name="viewport" content="width=device-width" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>EU Long-term Dataset with Multiple Sensors for Autonomous Driving</title>
    <link rel="stylesheet" href="css/wp.css" type="text/css" />
  </head>
  
  <body>
    <h1 id="logo">
      <br/><span style="color:#003399;">E</span><span style="color:#ffcc00;">U</span> Long-term Dataset with Multiple Sensors for Autonomous Driving
    </h1>
    
    <p style="text-align: left">--- Collected by our very own UTBM robocar ---</p>
    
    <p style="text-align: left">
      <img alt="utbm_robocar.jpg" height="315" src="images/utbm_robocar.jpg">&nbsp;&nbsp;&nbsp;
      <img alt="itinerary_longterm.png" height="315" src="images/itinerary_longterm.png">&nbsp;&nbsp;&nbsp;
      <img alt="itinerary_roundabout.png" height="315" src="images/itinerary_roundabout.png">
    </p>
    
    <h2>Description</h2>
    <p>This dataset was collected with our robocar (<b>in human driving mode of course</b>), equipped up to eleven heterogeneous sensors, in the downtown (for long-term data) and a suburb (for roundabout data) of <a href="http://www.montbeliard.fr/">Montb&eacute;liard</a> in France.
      The vehicle speed was limited to 50 km/h following the French traffic rules.
      For the long-term data, the driving distance is about 5.0 km (containing a small and a big road loop for loop-closure purpose) and the length of recorded data is about 16 minutes for each collection round.
      In addition to the typical eastern French city, users can feel the daily and seasonal changes of the city.
      For a quick overview, please refer to the following video.</p>
    <div style="text-align: left">
      <iframe width="560" height="315" src="https://www.youtube.com/embed/d8TNc3vVMLA" frameborder="0" allowfullscreen></iframe>&nbsp;&nbsp;&nbsp;
      <iframe width="560" height="315" src="https://www.youtube.com/embed/_xAmXNVMQbM" frameborder="0" allowfullscreen></iframe>
    </div>
    <p>For the roundabout data, the driving distance is about 4.2 km (containing 10 roundabouts with various sizes) and the length of recorded data is about 12 minutes.</p>
    
    <h2>Contributions</h2>
    <p>This dataset provides:</p>
    <ol>
      <li><a href="http://wiki.ros.org/">Robot Operating System (ROS)</a> <i>rosbag</i> files recording ground truth from two stereo cameras (a Bumblebee XB3 and a Bumblebee2), two Velodyne HDL-32E lidars, two Pixelink PL-B742F cameras with fisheye lens, an ibeo LUX 4L lidar, a Continental ARS 308 radar, a SICK LMS100-10000 laser rangefinder, a Magellan ProFlex 500 GNSS receiver with an RTK base station, and an Xsens MTi-28A53G25 IMU;
      <li>Data covering day, night, week, and season. As it captures daily and seasonal changes, this dataset is especially suitable for <b>long-term autonomy</b> research;
      <li>Intensive data for roundabout challenge, a very common road condition in France as well as in other European countries, not easy to handle even for humans.
      <li>Baselines based on relevant state-of-the-art methods, for the visual (monocular and stereo) and lidar odometry benchmarking (with ground-truth trajectories recorded by GPS/RTK).
    </ol>
    
    <h2>Citation</h2>
    <p>If you publish work based on, or using, this dataset, we would appreciate citations to the following:</p>

    <em>
      @article{utbm_robocar_dataset,<br>
        &nbsp;&nbsp;&nbsp;author    = {Zhi Yan and
                     Li Sun and
                     Tomas Krajnik and
                     Yassine Ruichek},<br>
        &nbsp;&nbsp;&nbsp;title     = {{EU} Long-term Dataset with Multiple Sensors for Autonomous Driving},<br>
        &nbsp;&nbsp;&nbsp;journal   = {CoRR},<br>
        &nbsp;&nbsp;&nbsp;volume    = {abs/1909.03330},<br>
        &nbsp;&nbsp;&nbsp;year      = {2019},<br>
        &nbsp;&nbsp;&nbsp;url       = {http://arxiv.org/abs/1909.03330},<br>
        &nbsp;&nbsp;&nbsp;archivePrefix = {arXiv},<br>
        &nbsp;&nbsp;&nbsp;eprint    = {1909.03330}<br>
      }
    </em>

    <h2>Recording platform</h2>
    <p style="text-align: left">
      <img alt="sensors.png" height="315" src="images/sensors.png">&nbsp;&nbsp;&nbsp;
      <img alt="sensors.png" height="315" src="images/ros_graph.jpg">
    </p>

    <p>Our design mainly adheres to the following two principles: 1) strengthen the visual scope as much as possible, and 2) maximize the overlapping area perceived by multiple sensors. In particular:</p>
    <ul>
      <li>Two stereo cameras, i.e. a front-facing Bumblebee XB3 and a back-facing Bumblebee2, are mounted on the front and rear of the roof, respectively.</li>
      <li>Two Velodyne HDL-32E lidars are mounted on the front portion of the vehicle roof, side by side.</li>
      <li>Two Pixelink PL-B742F cameras with fisheye lens are installed in the middle of the roof, facing the lateral sides of the vehicle.</li>
      <li>An ibeo LUX 4L lidar is embedded into the front bumper close to the y-axis of the car.</li>
      <li>A Continental ARS 308 radar is mounted in a position close to the ibeo LUX lidar.</li>
      <li>A SICK LMS100-10000 laser rangefinder (i.e. 2D lidar) facing the road is mounted on one side of the front bumper.</li>
      <li>A Magellan ProFlex 500 GNSS receiver is placed in the car with two antennas on the roof.</li>
      <li>An Xsens MTi-28A53G25 IMU is also placed inside the vehicle.</li>
    </ul>
    <p>For more details, please refer to our paper (in submission).</p>
    
    
    <h2>Challenges</h2>
    <p>Many new research challenges have been introduced in this dataset, such as:</p>
    <table style="border-spacing: 20px; text-align: center;">
      <tr>
	<td><img alt="sloping_road.jpg" height="168" src="images/challenges/sloping_road.jpg"></td>
	<td><img alt="shared_zone.jpg" height="168" src="images/challenges/shared_zone.jpg"></td>
	<td><img alt="diversion.jpg" height="168" src="images/challenges/diversion.jpg"></td>
	<td><img alt="roundabout.jpg" height="168" src="images/challenges/roundabout.jpg"></td>
	<td><img alt="night.jpg" height="168" src="images/challenges/night.jpg"></td>
      </tr>
      <tr>
	<td>sloping road</td>
	<td>shared zone</td>
	<td>construction bypass</td>
	<td>roundabout</td>
	<td>night</td>
      </tr>
      <tr>
	<td><img alt="snow.jpg" height="168" src="images/challenges/snow.jpg"></td>
	<td><img alt="right_overtaking.jpg" height="168" src="images/challenges/right_overtaking.jpg"></td>
	<td><img alt="crossing.jpg" height="168" src="images/challenges/crossing.jpg"></td>
	<td><img alt="pigeon.jpg" height="168" src="images/challenges/pigeon.jpg"></td>
	<td><img alt="police.jpg" height="168" src="images/challenges/police.jpg"></td>
      </tr>
      <tr>
	<td>snow</td>
	<td>right overtaking*</td>
	<td>crossing</td>
	<td>pigeon</td>
	<td>police</td>
      </tr>
    </table>
    <sup>*</sup><i>Aggressive driving / rule breaking behavior</i>
    
    <h2>Downloads</h2>
    <p><i>Please note that all rosbags are <a href="http://wiki.ros.org/rosbag/Commandline#rosbag_compress">compressed</a>, please <a href="http://wiki.ros.org/rosbag/Commandline#rosbag_decompress">decompress</a> them as needed.</i></p>
    
    <b>Long-term data:</b>
    <table style="border-spacing: 20px; text-align: left;">
      <tr><th>Date</th> <th>Local Time (Paris)</th> <th>Sensors</th> <th>Raw data</th></tr>
      <tr><td>2018-05-02 (Wed, evening)</td> <td>20:40 - 20:54 (14m30s)</td> <td>2 &times; Velodyne / ibeo / SICK / IMU / GPS-RTK</td> <td><a href="https://lcas.lincoln.ac.uk/owncloud/index.php/s/ZVjsgtnTYNJDTJN">rosbag</a></td></tr>
      <tr><td>2018-05-02 (Wed, night)</td> <td>21:28 - 21:42 (13m55s)</td> <td>2 &times; Velodyne / ibeo / SICK / IMU / GPS-RTK / Bumblebee XB3</td> <td><a href="https://lcas.lincoln.ac.uk/owncloud/index.php/s/G0aYdveU3rQwceh">rosbag</a> <a href="https://lcas.lincoln.ac.uk/owncloud/index.php/s/HCRhQa4kc6UROWk">(images)</a><sup>/</sup></td></tr>
      <tr><td>2018-07-13 (Fri, sunny)</td> <td>14:16 - 14:33 (16m59s)</td> <td>2 &times; Velodyne / ibeo / SICK / IMU / GPS-RTK</td> <td><a href="https://lcas.lincoln.ac.uk/owncloud/index.php/s/kAYErMEk1GNH4vq">rosbag</a></td></tr>
      <tr><td>2018-07-16 (Mon, sunny)</td> <td>16:10 - 16:26 (15m59s)</td> <td>2 &times; Velodyne / ibeo / SICK / IMU / GPS-RTK</td> <td><a href="https://lcas.lincoln.ac.uk/owncloud/index.php/s/vrr92pz1ZOoNQDR">rosbag</a></td></tr>
      <tr><td>2018-07-17 (Tue, sunny)</td> <td>15:40 - 15:56 (15m59s)</td> <td>2 &times; Velodyne / ibeo / SICK / IMU / GPS-RTK</td> <td><a href="https://lcas.lincoln.ac.uk/owncloud/index.php/s/2fAA1HudbBUsqZ0">rosbag</a></td></tr>
      <tr><td>2018-07-18 (Wed, sunny)</td> <td>15:04 - 15:21 (16m39s)</td> <td>2 &times; Velodyne / ibeo / SICK / IMU / GPS-RTK</td> <td><a href="https://lcas.lincoln.ac.uk/owncloud/index.php/s/eBwzzgYMNLNWobk">rosbag</a><sup>+</sup></td></tr>
      <tr><td>2018-07-19 (Thu, sunny)</td> <td>16:15 - 16:31 (15m26s)</td> <td>2 &times; Velodyne / ibeo / SICK / IMU / GPS-RTK</td> <td><a href="https://lcas.lincoln.ac.uk/owncloud/index.php/s/KfItDFgwwis5Xrk">rosbag</a><sup>-</sup></td></tr>
      <tr><td>2018-07-20 (Fri, cloudy)</td> <td>14:35 - 14:51 (16m45s)</td> <td>2 &times; Velodyne / ibeo / SICK / IMU / GPS-RTK</td> <td><a href="https://lcas.lincoln.ac.uk/owncloud/index.php/s/WUL3apyRIs9oyKE">rosbag</a></td></tr>
      <tr><td>2019-01-10 (Fri, snow)</td> <td>09:06 - 09:17 (10m59s)</td> <td>1 &times; Velodyne / ibeo / SICK / IMU</td> <td><a href="https://lcas.lincoln.ac.uk/owncloud/index.php/s/0tEXbkcfhn60bzA">rosbag</a><sup>*</sup></td></tr>
      <tr><td>2019-01-31 (Fri， snow)</td> <td>08:54 - 09:10 (15m59s)</td> <td>1 &times; Velodyne / ibeo / SICK / IMU / GPS</td> <td><a href="https://lcas.lincoln.ac.uk/owncloud/index.php/s/BYyvLbQpRx17j0p">rosbag</a><sup>*</sup></td></tr>
      <tr><td>2019-04-18 (Thu， sunny)</td> <td>11:07 - 11:22 (14m55s)</td> <td>1 &times; Velodyne / ibeo / SICK / IMU / GPS-RTK / radar</td> <td><a href="https://lcas.lincoln.ac.uk/owncloud/index.php/s/HfWJVQP3RI27lwo">rosbag</a></td></tr>
      <tr><td colspan="4"><sup>+</sup><i>Only partial GPS-RTK data.</i></td></tr>
      <tr><td colspan="4"><sup>-</sup><i>Best data quality, recommended for evaluation.</i></td></tr>
      <tr><td colspan="4"><sup>*</sup><i>Only part of the itinerary recorded due to adverse weather conditions.</i></td></tr>
      <tr><td colspan="4"><sup>/</sup><i>You might want to <a href="http://wiki.ros.org/bag_tools">add_header_time_offset.py</a></i></td></tr>
    </table>
    
    <b>Roundabout data:</b>
    <table style="border-spacing: 20px; text-align: left;">
      <tr><th>Date</th> <th>Local Time (Paris)</th> <th>Sensors</th> <th>Raw data</th></tr>
      <tr><td>2019-04-12 (Fri, cloudy)</td> <td>18:14 - 18:26 (12m10s)</td> <td>1 &times; Velodyne / ibeo / SICK / IMU / GPS-RTK / radar</td> <td><a href="https://lcas.lincoln.ac.uk/owncloud/index.php/s/5DGVDqfgGQIYBE3">rosbag</a></td></tr>
      <tr><td>2019-04-18 (Thu, sunny)</td> <td>12:03 - 12:15 (11m59s)</td> <td>1 &times; Velodyne / ibeo / SICK / IMU / GPS-RTK / radar</td> <td><a href="https://lcas.lincoln.ac.uk/owncloud/index.php/s/AViuCyw9Of7D5ph">rosbag</a></td></tr>
    </table>
    
    <p><i>Please note that, 1) it is a growing dataset and will be incrementally published, and 2) images will be incrementally available after processing to meet the GDPR requirements.</i></p>
    
    <h2>How to play</h2>
    <table>
      <tr><td bgcolor="#DCDCDC">roslaunch <a href="https://github.com/epan-utbm/utbm_robocar_dataset/blob/baselines/launch/utbm_robocar_dataset.launch">utbm_dataset_play.launch</a> bag:=path_to_your_rosbag</td></tr>
    </table>
    <p>By using the provided launch file, you will have:</p>
    <ol>
      <li> Point cloud conversions for the Velodyne lidars, and without any spurious data (caused by blockage or reflections from the opposing sensors).
      <li> The output of the object tracking functionality of the ibeo LUX lidar.
      <li> A complete and aligned tf tree.
    </ol>
    
    <h2>Baselines</h2>
    <p><a href="https://github.com/epan-utbm/utbm_robocar_dataset">https://github.com/epan-utbm/utbm_robocar_dataset</a></p>

    <h2>Related Development</h2>
    <p><a href="https://github.com/epan-utbm/image_anonymization">Image anonymization tool</a></p>
 
    <h2>Privacy</h2>
    <p>We take privacy very seriously and handle personal data in line with the <a href="https://eur-lex.europa.eu/eli/reg/2016/679/oj">General Data Protection Regulation (GDPR) (EU) 2016/679</a>. To this end, we used <a href="https://github.com/epan-utbm/image_anonymization">deep learning-based methods</a> to post-process the images in order to blur face and license plate information. However, if you still find yourself or your personal belongings in the data, please contact us and we will immediately remove the corresponding information from the dataset.</p>

    <h2>License</h2>
    <p>
      <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a>
      <br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
      <br />Copyright (c) 2018 <a href="https://yzrobot.github.io/">Zhi Yan</a>, <a href="https://sites.google.com/site/lisunspersonalsite/">Li Sun</a>, <a href="http://labe.felk.cvut.cz/~tkrajnik/">Tomas Krajnik</a>, and <a href="https://www.researchgate.net/profile/Yassine_Ruichek">Yassine Ruichek</a>.
    </p>
    
    <h2>Funding</h2>
    <p>This work was supported by the Quality Research Bonus (BQR) of the University of Technology of Belfort-Montb&eacute;liard (UTBM), the Contrat de Plan &Eacute;tat-R&eacute;gion (CPER) 2015-2020 Mobilitech, and the PHC Barrande programme under grant agreement No. 40682ZH (3L4AV).</p>
    
    <h2>Sponsors</h2>
    <a href="https://epan-utbm.github.io/"><img alt="epan_logo.png" src="images/epan_logo.png"/></a>&nbsp;&nbsp;&nbsp;
    <a href="http://www.ciad-lab.fr/"><img alt="ciad_logo.png" src="images/ciad_logo.png"/></a>&nbsp;&nbsp;&nbsp;
    <a href="https://www.utbm.fr/"><img alt="utbm_logo.png" src="images/utbm_logo.png"/></a>&nbsp;&nbsp;&nbsp;
    <a href="https://lcas.lincoln.ac.uk/wp/"><img alt="lcas_logo.png" src="images/lcas_logo.png"/></a>&nbsp;&nbsp;&nbsp;
    <a href="https://www.nvidia.com/"><img alt="nvida_logo.png" src="images/nvidia_logo.png"/></a>

    <h2>Acknowledgment</h2>
    <p>The authors would like to thank <a href="http://www.multiagent.fr/People:Abbas-turki_abdeljalil">Abdeljalil Abbas-Turki</a>, <a href="http://www.multiagent.fr/People:Lamotte_olivier">Olivier Lamotte</a>, <a href="https://www.researchgate.net/profile/Jocelyn_Buisson">Jocelyn Buisson</a>, and <a href="https://www.researchgate.net/profile/Fahad_Lateef">Fahad Lateef</a> for their help in building the dataset, the <a href="https://lcas.lincoln.ac.uk/wp/">Lincoln Centre for Autonomous Systems (L-CAS)</a> for hosting the dataset, and the reviewers of <a href="https://www.icra2020.org/">ICRA 2020</a> in helping improve the manuscript.</p>

  </body>
</html>

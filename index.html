<!DOCTYPE html>
<html>
  <head>
    <meta name="viewport" content="width=device-width" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>UTBM Multisensor ROS-based Dataset for Autonomous Driving</title>
    <link rel="stylesheet" href="css/wp.css" type="text/css" />
  </head>
  
  <body>
    <h1 id="logo">
      <a href="https://www.utbm.fr/"><img alt="utbm_logo.png" src="images/utbm_logo.png"/></a>&nbsp;&nbsp;&nbsp;
      <a href="https://epan-utbm.github.io/"><img alt="epan_logo.png" src="images/epan_logo.png"/></a>
      <br/>UTBM Multisensor ROS-based Dataset for Autonomous Driving
    </h1>
    
    <p style="text-align: left">--- collected by our very own UTBM robocar</p>
    
    <p style="text-align: left">
      <img alt="utbm_robocar.jpg" height="315" src="images/utbm_robocar.jpg">&nbsp;&nbsp;&nbsp;
      <img alt="itinerary_longterm.png" height="315" src="itinerary_longterm.png">&nbsp;&nbsp;&nbsp;
      <img alt="itinerary_roundabout.png" height="315" src="itinerary_roundabout.png">
    </p>
    
    <h2>Description</h2>
    <p>This dataset was collected with our robocar equipped up to ten heterogeneous sensors, in the old town of <a href="http://www.montbeliard.fr/">Montb√©liard</a> in France. The driving distance is up to five kilometers (containing a large and a small loop) and the length of recorded data is about 16 minutes per collection round. In addition to the typical eastern French city, users can feel the daily changes of the city. For a quick overview, please refer to the following video.</p>
    <div style="text-align: left"><iframe width="560" height="315" src="https://www.youtube.com/embed/d8TNc3vVMLA" frameborder="0" allowfullscreen></iframe></div>
    
    <h2>Contributions</h2>
    <p>This dataset provides:</p>
    <ol>
      <li><a href="http://wiki.ros.org/">Robot Operating System (ROS)</a> <i>rosbag</i> files recording <b>ground truth</b> from Two Velodyne HDL-32E 3D lidars, an ibeo LUX 4L 3D lidar, a SICK LMS100-10000 2D lidar, two Bumblebee stereo cameras, Two Pixelink PL-B742F cameras with fisheye lens, A Magellan ProFlex 500 GNSS receiver with RTK correction, and an Xsens MTi-28A53G25 IMU;
      <li>one week of data, the same route, recorded once a day. Since it captures daily changes, our dataset is especially suitable for long-term autonomy research;
      <li> baselines based on relevant state-of-the-art methods, for the monocular, stereo, lidar odometry and visual localization challenges.
    </ol>
    
    <h2>Citation</h2>
    <p>If you publish work based on, or using, this dataset, we would appreciate citations to the following:</p>
    <p><font color="red">manuscript under review ...</font></p>
    
    <h2>Recording platform</h2>
    <p style="text-align: left">
      <img alt="sensors.png" height="315" src="images/sensors.png">
    </p>
    <p>
      Our design mainly adheres to the following two principles: 1) strengthen the visual scope as much as possible, and 2) maximize the overlapping area perceived by multiple sensors. In particular,
      <ul>
	<li>two stereo cameras, i.e. a front-facing Bumblebee XB3 and a back-facing Bumblebee2, are mounted on the front and rear of the roof, respectively;</li>
	<li>two Velodyne HDL-32E 3D lidars are mounted on the front portion of the vehicle roof, side by side;</li>
	<li>two Pixelink PL-B742F cameras with the fisheye lens are installed in the middle of the roof, facing the lateral sides of the car;</li>
	<li>an ibeo LUX 4L 3D lidar is embedded into the front bumper close to the y-axis of the car;</li>
	<li>a Continental ARS 308 radar is mounted in a position close to the ibeo LUX lidar;</li>
	<li>a SICK LMS100-10000 2D lidar facing the road is mounted on one side of the front bumper;</li>
	<li>a Magellan ProFlex 500 GNSS receiver is placed in the car with two antennas on the roof;</li>
        <li>an Xsens MTi-28A53G25 IMU is placed inside the vehicle.</li>
      </ul>
    </p>
    
    <h2>Challenges</h2>
    <p>Many new research challenges have been introduced in this dataset, such as sloping road, shared zone, diversion, roundabout, etc.</p>
    <table style="border-spacing: 20px; text-align: center;">
      <tr>
	<td><img alt="sloping_road.jpg" height="168" src="images/sloping_road.jpg"></td>
	<td><img alt="shared_zone.jpg" height="168" src="images/shared_zone.jpg"></td>
	<td><img alt="diversion.jpg" height="168" src="images/diversion.jpg"></td>
	<td><img alt="roundabout.jpg" height="168" src="images/roundabout.jpg"></td>
      </tr>
      <tr>
	<td>sloping road</td>
	<td>shared zone</td>
	<td>diversion</td>
	<td>roundabout</td>
      </tr>
    </table>
    
    <h2>Downloads</h2>
    <table style="border-spacing: 20px; text-align: center;">
      <tr><th>Date</th> <th>Time</th> <th>Sensor</th> <th>Raw data</th></tr>
      <tr><td>2018-07-16</td> <td>16:10-16:26</td> <td>all lidars</td> <td><a href="https://lcas.lincoln.ac.uk/owncloud/index.php/s/ZC9lIvVEa61jgIr/download?path=%2F&files=utbm_robocar_dataset_20180716_lidars.bag">rosbag</a></td></tr>
      <tr><td>2018-07-17</td> <td>15:40-15:56</td> <td>all lidars</td> <td><a href="https://lcas.lincoln.ac.uk/owncloud/index.php/s/ZC9lIvVEa61jgIr/download?path=%2F&files=utbm_robocar_dataset_20180717_lidars.bag">rosbag</a></td></tr>
      <tr><td>2018-07-18</td> <td>15:04-15:20</td> <td>all lidars</td> <td><a href="https://lcas.lincoln.ac.uk/owncloud/index.php/s/ZC9lIvVEa61jgIr/download?path=%2F&files=utbm_robocar_dataset_20180718_lidars.bag">rosbag</a></td></tr>
      <tr><td>2018-07-19</td> <td>16:15-16:50</td> <td>all lidars</td> <td><a href="https://lcas.lincoln.ac.uk/owncloud/index.php/s/ZC9lIvVEa61jgIr/download?path=%2F&files=utbm_robocar_dataset_20180719_lidars.bag">rosbag</a></td></tr>
      <tr><td>2018-07-20</td> <td>16:35-16:51</td> <td>all lidars</td> <td><a href="https://lcas.lincoln.ac.uk/owncloud/index.php/s/ZC9lIvVEa61jgIr/download?path=%2F&files=utbm_robocar_dataset_20180720_lidars.bag">rosbag</a></td></tr>
    </table>
	  
    <p><i>Please note that, 1) it is a growing dataset and will be incrementally published,
	                    2) images will be available after processing to meet the GDPR requirements.</i></p>
	
    <h2>Baselines</h2>
    <p><a href="https://github.com/epan-utbm/utbm_robocar_dataset">https://github.com/epan-utbm/utbm_robocar_dataset</a></p>
    
    <h2>License</h2>
    <p>
      <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a>
      <br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
      <br />Copyright (c) 2018 <a href="https://yzrobot.github.io/">Zhi Yan</a>, <a href="https://sites.google.com/site/lisunspersonalsite/">Li Sun</a>, and <a href="https://www.researchgate.net/profile/Yassine_Ruichek">Yassine Ruichek</a>.
    </p>
    
    <h2>Funding</h2>
    <p>This work was supported by the Quality Research Bonus (BQR) of the University of Technology of Belfort-Montb&eacute;liard (UTBM), the Contrat de Plan &Eacute;tat-R&eacute;gion (CPER) 2015-2020 Mobilitech, and the PHC Barrande programme under grant agreement No. 40682ZH (3L4AV).</p>
  </body>

    <h2>Sponsors</h2>
    <a href="https://lcas.lincoln.ac.uk/wp/"><img alt="lcas_logo.png" src="images/lcas_logo.png"/></a>
  </body>
	
    <h2>Acknowledgment</h2>
    <p>The authors would like to thank <a href="http://www.multiagent.fr/People:Abbas-turki_abdeljalil">Abdeljalil Abbas-Turki</a>, <a href="http://www.multiagent.fr/People:Lamotte_olivier">Olivier Lamotte</a>, <a href="https://www.researchgate.net/profile/Jocelyn_Buisson">Jocelyn Buisson</a>, and <a href="https://www.researchgate.net/profile/Fahad_Lateef">Fahad Lateef</a> for their help in building the dataset, and the <a href="https://lcas.lincoln.ac.uk/wp/">Lincoln Centre for Autonomous Systems (L-CAS)</a> for hosting the dataset.</p>
</html>
